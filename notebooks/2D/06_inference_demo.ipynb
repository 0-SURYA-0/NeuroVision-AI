{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492dd834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from tqdm.auto import tqdm\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f1304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_DIR = os.path.abspath(os.getcwd())\n",
    "ROOT_DIR = os.path.abspath(os.path.join(NB_DIR, \"..\"))\n",
    "if ROOT_DIR not in sys.path:\n",
    "    sys.path.append(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65835019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.model import TumorNet34Bayes\n",
    "from core.utils import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ffacb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_RESULTS = r\"..\\results\"\n",
    "CKPT_DIR     = os.path.join(ROOT_RESULTS, \"checkpoints\")\n",
    "VIZ_DIR      = os.path.join(ROOT_RESULTS, \"visualizations\")\n",
    "for d in [ROOT_RESULTS, CKPT_DIR, VIZ_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0275e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7753a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "X_test = np.load(os.path.join(ROOT_DIR, \"data\", \"processed\", \"X_test.npy\"))\n",
    "y_test = np.load(os.path.join(ROOT_DIR, \"data\", \"processed\", \"y_test.npy\"))\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32).permute(0,3,1,2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdde83de",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = os.path.join(CKPT_DIR, \"model_weights_best.pth\")  \n",
    "assert os.path.exists(weights_path), f\"Checkpoint not found: {weights_path}\"\n",
    "model = TumorNet34Bayes(dropout_p=0.4).to(device)\n",
    "model.load_state_dict(torch.load(weights_path, map_location=device))\n",
    "model.eval()\n",
    "print(\"‚úÖ Loaded:\", weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e34bb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_cam(model, image, target_layer=\"layer4\"):\n",
    "    \"\"\"\n",
    "    image: (3,224,224) on device, float\n",
    "    returns: (cam[224,224], prob, pred_int)\n",
    "    \"\"\"\n",
    "    image = image.unsqueeze(0)\n",
    "    grads, activs = [], []\n",
    "\n",
    "    def fhook(module, inp, out): activs.append(out.detach())\n",
    "    def bhook(module, gin, gout): grads.append(gout[0].detach())\n",
    "\n",
    "    layer = dict([*model.named_modules()])[target_layer]\n",
    "    fh = layer.register_forward_hook(fhook)\n",
    "    bh = layer.register_backward_hook(bhook)\n",
    "\n",
    "    model.zero_grad(set_to_none=True)\n",
    "    logits, probs, conf = model(image)     \n",
    "    prob = torch.sigmoid(logits).squeeze()\n",
    "    pred = (prob > 0.5).float()\n",
    "    prob.backward()  \n",
    "\n",
    "    g, a = grads[0], activs[0]               \n",
    "    weights = g.mean(dim=(2,3), keepdim=True)\n",
    "    cam = (weights * a).sum(dim=1).squeeze()\n",
    "    cam = torch.relu(cam)\n",
    "    cam = cam / (cam.max() + 1e-8)\n",
    "    cam = cv2.resize(cam.detach().cpu().numpy(), (224,224))\n",
    "\n",
    "    fh.remove(); bh.remove()\n",
    "    return cam, float(prob.item()), int(pred.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d49d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def mc_dropout_pred(model, image, T=20):\n",
    "    model.eval()  \n",
    "    probs = []\n",
    "    for _ in range(T):\n",
    "        def enable_dropout(m):\n",
    "            if type(m) == torch.nn.Dropout:\n",
    "                m.train()\n",
    "        model.apply(enable_dropout)\n",
    "\n",
    "        logits, *_ = model(image.unsqueeze(0))\n",
    "        p = torch.sigmoid(logits).item()\n",
    "        probs.append(p)\n",
    "    probs = np.array(probs)\n",
    "    return float(probs.mean()), float(probs.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2e3d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SHOW = min(3, len(X_test))\n",
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "for i in range(N_SHOW):\n",
    "    img_t = X_test_t[i]\n",
    "    cam, conf, pred = grad_cam(model, img_t, target_layer=\"layer4\")\n",
    "    mean_p, std_p = mc_dropout_pred(model, img_t, T=20)\n",
    "\n",
    "    base_img = (X_test[i] * 255).astype(np.uint8)\n",
    "    heatmap = (plt.cm.jet(cam)[:, :, :3] * 255).astype(np.uint8)\n",
    "    overlay = cv2.addWeighted(base_img, 1.0, heatmap, 0.45, 0)\n",
    "\n",
    "    plt.subplot(1, N_SHOW, i + 1)\n",
    "    plt.imshow(overlay)\n",
    "    true_label = int(y_test[i])\n",
    "    title_color = \"green\" if pred == true_label else \"red\"\n",
    "    plt.title(\n",
    "        f\"True: {true_label}, Pred: {pred}\\nConf: {conf:.3f}, Unc: {std_p:.3f}\",\n",
    "        color=title_color,\n",
    "        fontsize=10\n",
    "    )\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0524b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(VIZ_DIR, \"doctor_demo.png\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(out_path, dpi=160)\n",
    "plt.show()\n",
    "print(f\"üñº Saved overlay preview ‚Üí {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9ba3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mean_probs, all_preds, all_labels = [], [], []\n",
    "pbar = tqdm(range(len(X_test_t)), desc=\"Testing (MC Dropout)\", leave=False)\n",
    "for i in pbar:\n",
    "    img_t = X_test_t[i]\n",
    "    mean_p, std_p = mc_dropout_pred(model, img_t, T=20)\n",
    "    all_mean_probs.append(mean_p)\n",
    "    all_preds.append(int(mean_p > 0.5))\n",
    "    all_labels.append(int(y_test[i]))\n",
    "\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "try:\n",
    "    auc = roc_auc_score(all_labels, all_mean_probs)\n",
    "except ValueError:\n",
    "    auc = float(\"nan\")\n",
    "f1  = f1_score(all_labels, all_preds)\n",
    "\n",
    "print(\"\\n==================== FINAL RESULTS ====================\")\n",
    "print(f\"ü©∫ Test Accuracy : {acc:.4f}\")\n",
    "print(f\"üìà Test AUC-ROC : {auc:.4f}\")\n",
    "print(f\"üîÅ Test F1-Score: {f1:.4f}\")\n",
    "print(\"üîÆ Uncertainty  : MC-Dropout std shown per example\")\n",
    "print(\"üñº Visuals      : Grad-CAM overlays saved in results/visualizations\")\n",
    "print(\"=======================================================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ced9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    \"test_size\": int(len(all_labels)),\n",
    "    \"accuracy\": float(acc),\n",
    "    \"auc\": float(auc) if not np.isnan(auc) else None,\n",
    "    \"f1\": float(f1)\n",
    "}\n",
    "with open(os.path.join(ROOT_RESULTS, \"inference_summary.json\"), \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print(f\"‚úÖ Saved summary ‚Üí {os.path.join(ROOT_RESULTS, 'inference_summary.json')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
