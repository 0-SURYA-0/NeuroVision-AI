{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb847186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ System path configured for 3D architecture modules\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(r\"c:\\Users\\surya\\NueroVisionAI\\core\\3D architecture\")\n",
    "\n",
    "print(\"✅ System path configured for 3D architecture modules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24441ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠\n",
      "3D BRAIN TUMOR SEGMENTATION EVALUATION\n",
      "COMPREHENSIVE RESULTS ANALYSIS\n",
      "🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠🧠\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import json\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "from metrics_3d import SegmentationMetrics\n",
    "from utils_3d import Config, format_time\n",
    "from visualize_3d import VolumeVisualizer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"🧠\" * 50)\n",
    "print(\"3D BRAIN TUMOR SEGMENTATION EVALUATION\")\n",
    "print(\"COMPREHENSIVE RESULTS ANALYSIS\")\n",
    "print(\"🧠\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "017b9ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 CHECKING MODEL ARTIFACTS:\n",
      "├── Artifacts directory: c:\\Users\\surya\\NueroVisionAI\\notebooks\\3D\\artifacts\n",
      "├── Outputs directory: c:\\Users\\surya\\NueroVisionAI\\outputs\\3d\n",
      "└── Checkpoints directory: c:\\Users\\surya\\NueroVisionAI\\checkpoints\\3d\n",
      "\n",
      "✅ TRAINED MODELS FOUND:\n",
      "├── best_model.pth (PyTorch checkpoint)\n",
      "├── artifacts/best_model.pth\n",
      "├── tumornet_best.pkl\n",
      "\n",
      "📈 LOADING TRAINING HISTORY:\n",
      "├── History file: training_history.json\n",
      "├── Total epochs: 7\n",
      "└── Data loaded successfully\n",
      "\n",
      "🔍 SCANNING FOR INFERENCE RESULTS:\n",
      "├── No inference results directory found\n",
      "\n",
      "📊 INFERENCE SUMMARY LOADED:\n",
      "├── Total cases: 209\n",
      "├── Successful cases: 0\n",
      "└── Processing time: 0.00s\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "config.data_dir = r\"c:\\Users\\surya\\NueroVisionAI\\data\\BrainWithTumor\"\n",
    "config.output_dir = r\"c:\\Users\\surya\\NueroVisionAI\\outputs\\3d\"\n",
    "config.checkpoint_dir = r\"c:\\Users\\surya\\NueroVisionAI\\checkpoints\\3d\"\n",
    "\n",
    "artifacts_dir = Path(r\"c:\\Users\\surya\\NueroVisionAI\\notebooks\\3D\\artifacts\")\n",
    "outputs_dir = Path(config.output_dir)\n",
    "checkpoints_dir = Path(config.checkpoint_dir)\n",
    "\n",
    "print(f\"\\n📂 CHECKING MODEL ARTIFACTS:\")\n",
    "print(f\"├── Artifacts directory: {artifacts_dir}\")\n",
    "print(f\"├── Outputs directory: {outputs_dir}\")\n",
    "print(f\"└── Checkpoints directory: {checkpoints_dir}\")\n",
    "\n",
    "model_files_found = []\n",
    "if (checkpoints_dir / \"best_model.pth\").exists():\n",
    "    model_files_found.append(\"best_model.pth (PyTorch checkpoint)\")\n",
    "if (artifacts_dir / \"best_model.pth\").exists():\n",
    "    model_files_found.append(\"artifacts/best_model.pth\")\n",
    "if (artifacts_dir / \"tumornet_best.pkl\").exists():\n",
    "    model_files_found.append(\"tumornet_best.pkl\")\n",
    "\n",
    "if model_files_found:\n",
    "    print(f\"\\n✅ TRAINED MODELS FOUND:\")\n",
    "    for model_file in model_files_found:\n",
    "        print(f\"├── {model_file}\")\n",
    "else:\n",
    "    print(f\"\\n❌ No trained models found. Run training notebook first!\")\n",
    "\n",
    "history_files = list(artifacts_dir.glob(\"*history*.json\"))\n",
    "if history_files:\n",
    "    print(f\"\\n📈 LOADING TRAINING HISTORY:\")\n",
    "    try:\n",
    "        with open(history_files[0], 'r') as f:\n",
    "            training_history = json.load(f)\n",
    "        print(f\"├── History file: {history_files[0].name}\")\n",
    "        \n",
    "        if isinstance(training_history, dict):\n",
    "            epoch_count = len(training_history.get('train_loss', training_history.get('loss', [])))\n",
    "            print(f\"├── Total epochs: {epoch_count}\")\n",
    "        elif isinstance(training_history, list):\n",
    "            print(f\"├── Total epochs: {len(training_history)}\")\n",
    "        else:\n",
    "            print(f\"├── History format: {type(training_history)}\")\n",
    "        \n",
    "        print(f\"└── Data loaded successfully\")\n",
    "    except Exception as e:\n",
    "        training_history = None\n",
    "        print(f\"├── Error loading history: {e}\")\n",
    "        print(f\"└── Continuing without training history\")\n",
    "else:\n",
    "    training_history = None\n",
    "    print(f\"\\n⚠️  No training history found\")\n",
    "\n",
    "print(f\"\\n🔍 SCANNING FOR INFERENCE RESULTS:\")\n",
    "inference_results_dir = outputs_dir / \"inference_results\"\n",
    "if inference_results_dir.exists():\n",
    "    segmentation_files = list(inference_results_dir.glob(\"*_segmentation.nii.gz\"))\n",
    "    probability_files = list(inference_results_dir.glob(\"*_probability.nii.gz\"))\n",
    "    uncertainty_files = list(inference_results_dir.glob(\"*_uncertainty.nii.gz\"))\n",
    "    \n",
    "    print(f\"├── Segmentation masks: {len(segmentation_files)}\")\n",
    "    print(f\"├── Probability maps: {len(probability_files)}\")\n",
    "    print(f\"└── Uncertainty maps: {len(uncertainty_files)}\")\n",
    "else:\n",
    "    segmentation_files = []\n",
    "    probability_files = []\n",
    "    uncertainty_files = []\n",
    "    print(f\"├── No inference results directory found\")\n",
    "\n",
    "summary_report_path = outputs_dir / \"inference_summary_report.json\"\n",
    "if summary_report_path.exists():\n",
    "    try:\n",
    "        with open(summary_report_path, 'r') as f:\n",
    "            inference_summary = json.load(f)\n",
    "        print(f\"\\n📊 INFERENCE SUMMARY LOADED:\")\n",
    "        print(f\"├── Total cases: {inference_summary['inference_summary']['total_cases']}\")\n",
    "        print(f\"├── Successful cases: {inference_summary['inference_summary']['successful_cases']}\")\n",
    "        print(f\"└── Processing time: {inference_summary['inference_summary']['total_processing_time_seconds']:.2f}s\")\n",
    "    except Exception as e:\n",
    "        inference_summary = None\n",
    "        print(f\"\\n⚠️  Error loading inference summary: {e}\")\n",
    "else:\n",
    "    inference_summary = None\n",
    "    print(f\"\\n⚠️  No inference summary report found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdd5cb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚠️  No segmentation files found for analysis\n",
      "└── Run inference notebook first to generate results\n"
     ]
    }
   ],
   "source": [
    "if segmentation_files:\n",
    "    print(f\"\\n🧠 ANALYZING SEGMENTATION RESULTS...\")\n",
    "    \n",
    "    metrics_calculator = SegmentationMetrics()\n",
    "    case_analyses = []\n",
    "    \n",
    "    for i, seg_file in enumerate(segmentation_files[:10]):\n",
    "        case_id = seg_file.stem.replace('_segmentation', '')\n",
    "        print(f\"\\n├── Analyzing Case: {case_id}\")\n",
    "        \n",
    "        try:\n",
    "            seg_img = nib.load(seg_file)\n",
    "            segmentation = seg_img.get_fdata()\n",
    "            \n",
    "            prob_file = inference_results_dir / f\"{case_id}_probability.nii.gz\"\n",
    "            if prob_file.exists():\n",
    "                prob_img = nib.load(prob_file)\n",
    "                probability_map = prob_img.get_fdata()\n",
    "            else:\n",
    "                probability_map = None\n",
    "            \n",
    "            uncertainty_file = inference_results_dir / f\"{case_id}_uncertainty.nii.gz\"\n",
    "            if uncertainty_file.exists():\n",
    "                unc_img = nib.load(uncertainty_file)\n",
    "                uncertainty_map = unc_img.get_fdata()\n",
    "            else:\n",
    "                uncertainty_map = None\n",
    "            \n",
    "            tumor_volume = np.sum(segmentation > 0)\n",
    "            total_volume = segmentation.size\n",
    "            tumor_percentage = (tumor_volume / total_volume) * 100\n",
    "            \n",
    "            max_probability = np.max(probability_map) if probability_map is not None else 0\n",
    "            mean_tumor_prob = np.mean(probability_map[segmentation > 0]) if probability_map is not None and tumor_volume > 0 else 0\n",
    "            mean_uncertainty = np.mean(uncertainty_map[segmentation > 0]) if uncertainty_map is not None and tumor_volume > 0 else 0\n",
    "            \n",
    "            analysis = {\n",
    "                'case_id': case_id,\n",
    "                'tumor_volume_voxels': int(tumor_volume),\n",
    "                'tumor_percentage': round(tumor_percentage, 2),\n",
    "                'max_probability': round(max_probability, 4),\n",
    "                'mean_tumor_probability': round(mean_tumor_prob, 4),\n",
    "                'mean_uncertainty': round(mean_uncertainty, 4),\n",
    "                'volume_shape': segmentation.shape,\n",
    "                'has_tumor': tumor_volume > 0\n",
    "            }\n",
    "            \n",
    "            case_analyses.append(analysis)\n",
    "            \n",
    "            print(f\"    ├── Tumor volume: {tumor_volume:,} voxels ({tumor_percentage:.1f}%)\")\n",
    "            print(f\"    ├── Max probability: {max_probability:.4f}\")\n",
    "            print(f\"    └── Mean tumor prob: {mean_tumor_prob:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    └── ❌ Error analyzing {case_id}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n📊 SEGMENTATION STATISTICS:\")\n",
    "    if case_analyses:\n",
    "        tumor_cases = [c for c in case_analyses if c['has_tumor']]\n",
    "        no_tumor_cases = [c for c in case_analyses if not c['has_tumor']]\n",
    "        \n",
    "        print(f\"├── Total cases analyzed: {len(case_analyses)}\")\n",
    "        print(f\"├── Cases with detected tumors: {len(tumor_cases)}\")\n",
    "        print(f\"├── Cases with no tumors: {len(no_tumor_cases)}\")\n",
    "        print(f\"└── Detection rate: {len(tumor_cases)/len(case_analyses)*100:.1f}%\")\n",
    "        \n",
    "        if tumor_cases:\n",
    "            volumes = [c['tumor_volume_voxels'] for c in tumor_cases]\n",
    "            percentages = [c['tumor_percentage'] for c in tumor_cases]\n",
    "            probabilities = [c['max_probability'] for c in tumor_cases]\n",
    "            \n",
    "            print(f\"\\n📈 TUMOR CHARACTERISTICS:\")\n",
    "            print(f\"├── Average volume: {np.mean(volumes):.0f} ± {np.std(volumes):.0f} voxels\")\n",
    "            print(f\"├── Volume range: {np.min(volumes):,} - {np.max(volumes):,} voxels\")\n",
    "            print(f\"├── Average percentage: {np.mean(percentages):.2f} ± {np.std(percentages):.2f}%\")\n",
    "            print(f\"├── Average max prob: {np.mean(probabilities):.4f} ± {np.std(probabilities):.4f}\")\n",
    "            print(f\"└── Probability range: {np.min(probabilities):.4f} - {np.max(probabilities):.4f}\")\n",
    "\n",
    "else:\n",
    "    case_analyses = []\n",
    "    print(f\"\\n⚠️  No segmentation files found for analysis\")\n",
    "    print(f\"└── Run inference notebook first to generate results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5c32846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "🎯 COMPREHENSIVE EVALUATION REPORT\n",
      "================================================================================\n",
      "\n",
      "📈 TRAINING PERFORMANCE:\n",
      "├── History entries: 7\n",
      "├── Latest loss: N/A\n",
      "└── Latest dice: N/A\n",
      "\n",
      "🏆 MODEL CHECKPOINT INFO:\n",
      "├── Best val Dice: 0.8974\n",
      "├── Epoch: 17\n",
      "├── Learning rate: N/A\n",
      "└── Checkpoint saved\n",
      "\n",
      "💾 DATA PROCESSING SUMMARY:\n",
      "├── BrainWithTumor: 1620 files\n",
      "├── Healthy: 1620 files\n",
      "├── TumorOnly: 1620 files\n",
      "└── Total data files: 4860\n",
      "\n",
      "🚀 INFERENCE PERFORMANCE:\n",
      "├── Total test cases: 209\n",
      "├── Successful inferences: 0\n",
      "├── Failed cases: 209\n",
      "├── Success rate: 0.0%\n",
      "├── Total processing time: 0.0s\n",
      "├── Average time per case: 0.00s\n",
      "\n",
      "📁 OUTPUT DIRECTORIES:\n",
      "├── Model artifacts: c:\\Users\\surya\\NueroVisionAI\\notebooks\\3D\\artifacts\n",
      "├── Inference results: c:\\Users\\surya\\NueroVisionAI\\outputs\\3d\\inference_results\n",
      "├── Checkpoints: c:\\Users\\surya\\NueroVisionAI\\checkpoints\\3d\n",
      "└── Summary reports: c:\\Users\\surya\\NueroVisionAI\\outputs\\3d\n",
      "\n",
      "🎉 EVALUATION COMPLETED SUCCESSFULLY!\n",
      "🔥 COMPREHENSIVE ANALYSIS | DETAILED METRICS | PRODUCTION READY\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"🎯 COMPREHENSIVE EVALUATION REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if training_history:\n",
    "    print(f\"\\n📈 TRAINING PERFORMANCE:\")\n",
    "    \n",
    "    if isinstance(training_history, dict):\n",
    "        train_losses = training_history.get('train_loss', training_history.get('loss', []))\n",
    "        val_losses = training_history.get('val_loss', training_history.get('val_loss', []))\n",
    "        val_dice_scores = training_history.get('val_dice', training_history.get('dice', []))\n",
    "        \n",
    "        if train_losses:\n",
    "            print(f\"├── Total epochs: {len(train_losses)}\")\n",
    "            print(f\"├── Final train loss: {train_losses[-1]:.4f}\")\n",
    "            if val_losses:\n",
    "                print(f\"├── Final val loss: {val_losses[-1]:.4f}\")\n",
    "            if val_dice_scores:\n",
    "                best_dice = max(val_dice_scores)\n",
    "                best_epoch = val_dice_scores.index(best_dice) + 1\n",
    "                print(f\"├── Best val Dice: {best_dice:.4f} (epoch {best_epoch})\")\n",
    "                print(f\"└── Final val Dice: {val_dice_scores[-1]:.4f}\")\n",
    "    elif isinstance(training_history, list):\n",
    "        print(f\"├── History entries: {len(training_history)}\")\n",
    "        if training_history and isinstance(training_history[0], dict):\n",
    "            latest_entry = training_history[-1]\n",
    "            print(f\"├── Latest loss: {latest_entry.get('loss', 'N/A')}\")\n",
    "            print(f\"└── Latest dice: {latest_entry.get('dice', 'N/A')}\")\n",
    "\n",
    "checkpoint_path = checkpoints_dir / \"best_model.pth\"\n",
    "if checkpoint_path.exists():\n",
    "    try:\n",
    "        import torch\n",
    "        checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)\n",
    "        print(f\"\\n🏆 MODEL CHECKPOINT INFO:\")\n",
    "        print(f\"├── Best val Dice: {checkpoint.get('best_val_dice', 'N/A'):.4f}\")\n",
    "        print(f\"├── Epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
    "        print(f\"├── Learning rate: {checkpoint.get('learning_rate', 'N/A')}\")\n",
    "        print(f\"└── Checkpoint saved\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n⚠️  Error loading checkpoint: {e}\")\n",
    "\n",
    "print(f\"\\n💾 DATA PROCESSING SUMMARY:\")\n",
    "data_folders = [\"BrainWithTumor\", \"Healthy\", \"TumorOnly\"]\n",
    "total_files = 0\n",
    "for folder in data_folders:\n",
    "    folder_path = Path(config.data_dir).parent / folder\n",
    "    if folder_path.exists():\n",
    "        count = len(list(folder_path.glob(\"*.nii.gz\")))\n",
    "        total_files += count\n",
    "        print(f\"├── {folder}: {count} files\")\n",
    "    else:\n",
    "        print(f\"├── {folder}: Directory not found\")\n",
    "\n",
    "print(f\"└── Total data files: {total_files}\")\n",
    "\n",
    "if inference_summary:\n",
    "    inference_info = inference_summary['inference_summary']\n",
    "    print(f\"\\n🚀 INFERENCE PERFORMANCE:\")\n",
    "    print(f\"├── Total test cases: {inference_info['total_cases']}\")\n",
    "    print(f\"├── Successful inferences: {inference_info['successful_cases']}\")\n",
    "    print(f\"├── Failed cases: {inference_info['failed_cases']}\")\n",
    "    \n",
    "    if inference_info['total_cases'] > 0:\n",
    "        success_rate = inference_info['successful_cases']/inference_info['total_cases']*100\n",
    "        print(f\"├── Success rate: {success_rate:.1f}%\")\n",
    "    else:\n",
    "        print(f\"├── Success rate: N/A\")\n",
    "    \n",
    "    print(f\"├── Total processing time: {format_time(inference_info['total_processing_time_seconds'])}\")\n",
    "    print(f\"├── Average time per case: {inference_info['average_time_per_case_seconds']:.2f}s\")\n",
    "    \n",
    "    case_results = inference_summary.get('case_results', [])\n",
    "    if case_results:\n",
    "        tumor_detected_cases = [c for c in case_results if c['tumor_detected']]\n",
    "        detection_rate = len(tumor_detected_cases)/len(case_results)*100\n",
    "        print(f\"└── Tumor detection rate: {len(tumor_detected_cases)}/{len(case_results)} ({detection_rate:.1f}%)\")\n",
    "\n",
    "if 'case_analyses' in locals() and case_analyses:\n",
    "    print(f\"\\n🔬 DETAILED ANALYSIS RESULTS:\")\n",
    "    print(f\"├── Cases analyzed: {len(case_analyses)}\")\n",
    "    \n",
    "    tumor_volumes = [c['tumor_volume_voxels'] for c in case_analyses if c['has_tumor']]\n",
    "    if tumor_volumes:\n",
    "        print(f\"├── Avg tumor volume: {np.mean(tumor_volumes):.0f} voxels\")\n",
    "        print(f\"├── Tumor volume std: {np.std(tumor_volumes):.0f} voxels\")\n",
    "        \n",
    "        tumor_probs = [c['mean_tumor_probability'] for c in case_analyses if c['has_tumor']]\n",
    "        print(f\"├── Avg tumor confidence: {np.mean(tumor_probs):.4f}\")\n",
    "        print(f\"└── Confidence std: {np.std(tumor_probs):.4f}\")\n",
    "\n",
    "print(f\"\\n📁 OUTPUT DIRECTORIES:\")\n",
    "print(f\"├── Model artifacts: {artifacts_dir}\")\n",
    "if 'inference_results_dir' in locals():\n",
    "    print(f\"├── Inference results: {inference_results_dir}\")\n",
    "print(f\"├── Checkpoints: {checkpoints_dir}\")\n",
    "print(f\"└── Summary reports: {outputs_dir}\")\n",
    "\n",
    "print(f\"\\n🎉 EVALUATION COMPLETED SUCCESSFULLY!\")\n",
    "print(f\"🔥 COMPREHENSIVE ANALYSIS | DETAILED METRICS | PRODUCTION READY\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
