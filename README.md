# ğŸ§  NueroVision AI

**Advanced 3D Brain Tumor Segmentation System with Deep Learning and Uncertainty Quantification**

A comprehensive AI-powered medical imaging platform for brain tumor detection and segmentation using state-of-the-art 3D U-Net architecture with uncertainty estimation and professional web interface.

## ğŸ”§ Tech Stack & Requirements

![Python](https://img.shields.io/badge/Python-3.8+-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red)
![FastAPI](https://img.shields.io/badge/FastAPI-Latest-green)
![React](https://img.shields.io/badge/React-18+-blue)
![TypeScript](https://img.shields.io/badge/TypeScript-5+-blue)
![NumPy](https://img.shields.io/badge/NumPy-1.24+-blue)
![NiBabel](https://img.shields.io/badge/NiBabel-5.2+-green)
![scikit-image](https://img.shields.io/badge/scikit--image-0.21+-orange)
![Tailwind](https://img.shields.io/badge/Tailwind-CSS-blue)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)

---

## âœ¨ Features

- ï¿½ **3D Brain Tumor Segmentation** using advanced 3D U-Net architecture
- ğŸ¥ **Multi-modal MRI Support** (T1, T1ce, T2, FLAIR) with intelligent preprocessing
- ğŸ¯ **Test-Time Augmentation (TTA)** for robust and reliable predictions
- ğŸ“Š **Uncertainty Quantification** with Monte Carlo Dropout and confidence estimation
- ğŸ”„ **Advanced Preprocessing Pipeline** with skull stripping, bias correction, and normalization
- ï¿½ **Post-processing Refinement** with morphological operations and component filtering
- ğŸ¨ **3D Visualization** with comprehensive volume rendering and slice views
- âš¡ **FastAPI Backend** with REST API for seamless integration
- ğŸ’» **Modern React Frontend** with TypeScript and Tailwind CSS
- ğŸ“Š **Real-time Metrics** including Dice score, IoU, and volume statistics  

---

## ğŸ—ï¸ Project Structure

```
NueroVisionAI/
â”‚â”€â”€ backend/                    # FastAPI backend
â”‚   â”œâ”€â”€ main.py                 # FastAPI application entry point
â”‚   â”œâ”€â”€ routes/                 # API route handlers
â”‚   â”‚   â”œâ”€â”€ auth.py            # Authentication endpoints
â”‚   â”‚   â”œâ”€â”€ predict.py         # Prediction API
â”‚   â”‚   â””â”€â”€ history.py         # Prediction history
â”‚   â”œâ”€â”€ models/                # Pre-trained model files
â”‚   â”‚   â”œâ”€â”€ tumornet_best.pkl  # Best model checkpoint
â”‚   â”‚   â””â”€â”€ tumornet.onnx      # ONNX model for deployment
â”‚   â”œâ”€â”€ services/              # Business logic
â”‚   â””â”€â”€ schemas.py             # Pydantic data models
â”‚
â”‚â”€â”€ core/                      # Core ML architecture
â”‚   â”œâ”€â”€ 2D architecture/       # 2D CNN models and utilities
â”‚   â””â”€â”€ 3D architecture/       # 3D U-Net implementation
â”‚       â”œâ”€â”€ model_3d.py        # 3D U-Net model architecture
â”‚       â”œâ”€â”€ train_3d.py        # Training pipeline
â”‚       â”œâ”€â”€ inference_3d.py    # Inference engine  
â”‚       â”œâ”€â”€ preprocess_3d.py   # Advanced preprocessing
â”‚       â”œâ”€â”€ postprocess_3d.py  # Post-processing pipeline
â”‚       â”œâ”€â”€ visualize_3d.py    # 3D visualization tools
â”‚       â”œâ”€â”€ metrics_3d.py      # Evaluation metrics
â”‚       â””â”€â”€ utils_3d.py        # Utility functions
â”‚
â”‚
â”‚â”€â”€ checkpoints/               # Model checkpoints
â”‚   â””â”€â”€ 3d/
â”‚       â””â”€â”€ best_model.pth    # Best trained model (Dice: 0.8974)
â”‚
â”‚â”€â”€ data/                     # BraTS dataset
â”‚   â”œâ”€â”€ BrainWithTumor/      # Tumor cases (T1, T1ce, T2, FLAIR)
â”‚   â”œâ”€â”€ Healthy/             # Healthy brain scans
â”‚   â””â”€â”€ TumorOnly/           # Tumor-only segmentation masks
â”‚
â”‚â”€â”€ frontend/                # React + TypeScript + Tailwind frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/      # UI components
â”‚   â”‚   â”‚   â”œâ”€â”€ AuthorsSection.tsx    # Team information
â”‚   â”‚   â”‚   â”œâ”€â”€ HeroSection.tsx       # Landing page hero
â”‚   â”‚   â”‚   â”œâ”€â”€ ImageUploader.tsx     # File upload component
â”‚   â”‚   â”‚   â””â”€â”€ ui/                   # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ pages/           # Page components
â”‚   â”‚   â”œâ”€â”€ services/        # API integration
â”‚   â”‚   â””â”€â”€ assets/          # Static assets
â”‚   â”œâ”€â”€ public/              # Public static files
â”‚   â”œâ”€â”€ package.json         # Frontend dependencies
â”‚   â””â”€â”€ vite.config.ts       # Vite configuration
â”‚
â”‚â”€â”€ notebooks/               # Research and development notebooks
â”‚   â”œâ”€â”€ 2D/                  # 2D CNN experiments
â”‚   â””â”€â”€ 3D/                  # 3D U-Net development
â”‚       â”œâ”€â”€ 01_explore_data_3d.ipynb      # Data exploration
â”‚       â”œâ”€â”€ 02_train_model_3d.ipynb       # Model training
â”‚       â”œâ”€â”€ 03_infer_segmentation_3d.ipynb # Inference pipeline
â”‚       â””â”€â”€ 04_evaluate_results_3d.ipynb   # Results evaluation
â”‚
â”‚â”€â”€ test_results/            # Test inference outputs
â”‚â”€â”€ outputs/                 # Training outputs and artifacts
â”‚â”€â”€ results/                 # Evaluation results and metrics
â”‚â”€â”€ test_model.py           # Standalone model testing script
â”‚â”€â”€ requirements.txt        # Python dependencies
â”‚â”€â”€ README.md              # Project documentation
â””â”€â”€ .gitignore            # Git ignore rules
```

---

## ğŸ› ï¸ Technology Stack

- **Deep Learning**: PyTorch, 3D U-Net, Light/Standard/Heavy architectures
- **Medical Imaging**: NiBabel, DICOM support, multi-modal MRI processing
- **Uncertainty Estimation**: Monte Carlo Dropout, Test-Time Augmentation
- **Preprocessing**: Skull stripping, bias correction, intensity normalization
- **Backend**: FastAPI, SQLAlchemy, PostgreSQL/SQLite, JWT authentication
- **Frontend**: React 18, TypeScript, Tailwind CSS, Vite, shadcn/ui
- **Visualization**: 3D volume rendering, slice-by-slice views, overlay masks
- **Deployment**: Docker, REST API, Web application  

---

## âš™ï¸ Setup & Installation

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-username/NueroVisionAI.git
cd NueroVisionAI
```

### 2ï¸âƒ£ Python Environment Setup

```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 3ï¸âƒ£ Backend Setup (FastAPI)

```bash
cd backend
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

The API will be available at **http://localhost:8000**
- API Documentation: **http://localhost:8000/docs**

### 4ï¸âƒ£ Frontend Setup (React + TypeScript)

```bash
cd frontend
npm install
npm run dev
```

The web application will be available at **http://localhost:5173**

### 5ï¸âƒ£ Model Testing

```bash
# Test the trained model with sample data
python test_model.py
```

### 6ï¸âƒ£ Training (Optional)

```bash
# Train a new model from scratch
cd "core/3D architecture"
python train_3d.py
```

---

## ğŸš€ Usage

1. **Open the Frontend UI** at http://localhost:5173
2. **Upload an MRI scan** (T1/T2/FLAIR format)
3. **Get Results**:
   - âœ… Tumor probability score
   - ğŸ“‰ Epistemic + Aleatoric uncertainty estimates
   - ğŸ”¥ Grad-CAM++ heatmap visualization

### API Endpoints

- `POST /predict` - Upload MRI scan for tumor detection
- `GET /health` - Health check endpoint
- `GET /docs` - Interactive API documentation

---

## ğŸ“Š Performance Results

### Model Performance
- **Validation Dice Score**: 0.8974 (89.74%)
- **Training Epochs**: 17 epochs for optimal convergence
- **Model Size**: 1,402,561 parameters (Light architecture)
- **Inference Time**: ~140ms per case (CPU), <50ms (GPU)

### Technical Achievements
- **Robust Preprocessing**: Handles various MRI protocols and scanner types
- **Uncertainty Quantification**: Reliable confidence estimation for clinical decision support
- **Multi-Modal Support**: Seamless integration of T1, T1ce, T2, and FLAIR sequences
- **3D Visualization**: Comprehensive volume rendering with interactive slice navigation
- **Clinical Integration**: DICOM-compatible processing pipeline

---

## ğŸ”¬ Model Architecture

### 3D U-Net Implementation

Our system features a sophisticated 3D U-Net architecture with multiple variants:

- **Light Model**: 1.4M parameters - Fast inference, suitable for resource-constrained environments
- **Standard Model**: Balanced architecture for optimal performance-efficiency trade-off  
- **Heavy Model**: Maximum capacity for highest accuracy requirements

### Key Technical Features

- **Multi-Scale Processing**: Handles 3D volumes with adaptive input sizing (64Â³, 128Â³, 256Â³)
- **Advanced Preprocessing**: 
  - Skull stripping and brain extraction
  - Bias field correction using N4ITK
  - Intensity normalization and standardization
  - Isotropic resampling for consistent voxel spacing
- **Uncertainty Quantification**: 
  - Monte Carlo Dropout for epistemic uncertainty
  - Test-Time Augmentation (TTA) for robust predictions
  - Confidence thresholding and reliability estimation
- **Post-Processing Pipeline**:
  - Connected component analysis
  - Morphological operations (opening, closing)
  - Hole filling and surface smoothing
  - Volume statistics and quality metrics

---

## ğŸ“ Key Files

- `core/3D architecture/model_3d.py` - 3D U-Net architecture implementation
- `core/3D architecture/train_3d.py` - Complete training pipeline
- `core/3D architecture/inference_3d.py` - Inference engine with TTA
- `core/3D architecture/preprocess_3d.py` - Advanced preprocessing pipeline
- `backend/main.py` - FastAPI application entry point
- `frontend/src/components/` - React components with TypeScript
- `test_model.py` - Standalone model testing script
- `checkpoints/3d/best_model.pth` - Trained model checkpoint

---

## ğŸ“ˆ Development Roadmap

- [ ] Deploy on cloud platform (Docker + AWS/GCP)
- [ ] Add support for additional MRI modalities (Diffusion, Perfusion)
- [ ] Implement clinical-grade user interface
- [ ] Add model performance benchmarking
- [ ] Integration with medical imaging standards (DICOM)

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgements

- [BRATS Dataset](https://www.med.upenn.edu/sbia/brats2018.html) for brain tumor MRI scans
- [PyTorch](https://pytorch.org/) for the deep learning framework
- [Grad-CAM++](https://arxiv.org/abs/1710.11063) for explainable AI visualizations
- [FastAPI](https://fastapi.tiangolo.com/) for the backend framework
- [React](https://reactjs.org/) and [Tailwind CSS](https://tailwindcss.com/) for the frontend

---

## ğŸ“ Contact & Support

For questions, suggestions, or collaboration opportunities:
- **Email**: team@neurovision.ai
- **Project Repository**: [GitHub](https://github.com/your-username/NueroVisionAI)

---

<div align="center">
  <strong>â­ Star this repo if you found it helpful!</strong>
</div>
